# ğŸ—ï¸ NYC Building Permit Clustering: MPI-Parallel Analysis on HPC

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![MPI](https://img.shields.io/badge/MPI-mpi4py-green.svg)](https://mpi4py.readthedocs.io/)
[![HPC](https://img.shields.io/badge/HPC-SeaWulf-orange.svg)](https://it.stonybrook.edu/services/high-performance-computing)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **AMS 598: Big Data Analysis** - Final Project  
> Stony Brook University, Fall 2024

## ğŸ“‹ Project Overview

This project performs **large-scale clustering analysis** on NYC Department of Buildings (DOB) Permit Issuance data using **MPI-parallelized algorithms** on a High-Performance Computing (HPC) cluster. We analyze over **1.8 million building permits** to discover patterns in NYC's construction activities.

### ğŸ¯ Key Objectives

1. **Scalable Clustering**: Implement distributed K-Means and Hierarchical clustering using MPI
2. **Performance Analysis**: Evaluate speedup and efficiency using Amdahl's Law
3. **Geographic Insights**: Discover spatial and temporal patterns in NYC construction permits
4. **Algorithm Comparison**: Compare baseline vs. MPI-parallel implementations

---

## ğŸ—‚ï¸ Project Structure

```
NYC-Permit-Clustering-MPI/
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“ clustering/          # Core clustering algorithms
â”‚   â”‚   â”œâ”€â”€ kmeans_baseline.py      # Serial K-Means implementation
â”‚   â”‚   â”œâ”€â”€ kmeans_mpi.py           # MPI-parallel K-Means (MapReduce style)
â”‚   â”‚   â”œâ”€â”€ hierarchical_clustering.py  # Serial Hierarchical clustering
â”‚   â”‚   â”œâ”€â”€ hierarchical_mpi.py     # MPI-parallel Hierarchical clustering
â”‚   â”‚   â””â”€â”€ bfr_mpi.py              # BFR algorithm for streaming data
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ analysis/            # Analysis and visualization
â”‚   â”‚   â”œâ”€â”€ eda.py                  # Exploratory Data Analysis
â”‚   â”‚   â”œâ”€â”€ dim_reduction.py        # PCA, UMAP, t-SNE
â”‚   â”‚   â”œâ”€â”€ evaluation.py           # Silhouette, Davies-Bouldin scores
â”‚   â”‚   â”œâ”€â”€ visualization.py        # Cluster visualizations
â”‚   â”‚   â”œâ”€â”€ cluster_interpretation.py   # Cluster profiling
â”‚   â”‚   â”œâ”€â”€ geographic_analysis.py  # NYC geographic visualizations
â”‚   â”‚   â””â”€â”€ hybrid_interpretation.py    # Combined analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ utils/               # Utilities and configuration
â”‚   â”‚   â”œâ”€â”€ config.py               # Centralized configuration
â”‚   â”‚   â”œâ”€â”€ data_prep.py            # Data preprocessing pipeline
â”‚   â”‚   â”œâ”€â”€ validation_fixed.py     # Data validation
â”‚   â”‚   â”œâ”€â”€ compute_mpi_metrics.py  # MPI performance metrics
â”‚   â”‚   â”œâ”€â”€ amdahl_visualization.py # Speedup/efficiency plots
â”‚   â”‚   â””â”€â”€ curse_dimensionality.py # Dimensionality analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ simulation_baseline.py  # Baseline simulation
â”‚   â”œâ”€â”€ simulation_mpi.py       # MPI simulation
â”‚   â””â”€â”€ presentation_summary.py # Results summary generator
â”‚
â”œâ”€â”€ ğŸ“ slurm/                   # HPC job scripts
â”‚   â”œâ”€â”€ step1_data_prep.slurm
â”‚   â”œâ”€â”€ step2a_dim_reduction.slurm
â”‚   â”œâ”€â”€ step2b_eda.slurm
â”‚   â”œâ”€â”€ step3a_kmeans_baseline.slurm
â”‚   â”œâ”€â”€ step3b_hierarchical_baseline.slurm
â”‚   â”œâ”€â”€ step4a_kmeans_mpi.slurm
â”‚   â”œâ”€â”€ step4b_hierarchical_mpi.slurm
â”‚   â”œâ”€â”€ step5a_evaluation.slurm
â”‚   â”œâ”€â”€ step5b_visualization.slurm
â”‚   â”œâ”€â”€ step5c_cluster_interpretation.slurm
â”‚   â”œâ”€â”€ step5d_hybrid_interpretation.slurm
â”‚   â”œâ”€â”€ step5e_geographic_viz_by_era.slurm
â”‚   â”œâ”€â”€ step6_amdahl_viz.slurm
â”‚   â””â”€â”€ step7_compute_metrics.slurm
â”‚
â”œâ”€â”€ ğŸ“ results/                 # Output directory
â”‚   â”œâ”€â”€ ğŸ“ figures/             # Generated visualizations
â”‚   â”œâ”€â”€ ğŸ“ metrics/             # Performance metrics
â”‚   â””â”€â”€ ğŸ“ clusters/            # Cluster assignments
â”‚
â”œâ”€â”€ ğŸ“ docs/                    # Documentation
â”‚
â””â”€â”€ README.md
```

---

## ğŸ”¬ Methodology

### Data Processing Pipeline

```
Raw Data (1.8M+ permits)
        â†“
    Cleaning & Feature Engineering (23 features)
        â†“
    Dimensionality Reduction (PCA â†’ 95% variance)
        â†“
    Clustering (K-Means, Hierarchical)
        â†“
    Evaluation & Visualization
```

### Features Used for Clustering

| Category | Features |
|----------|----------|
| **Geographic** | Latitude, Longitude, Council District, Census Tract |
| **Temporal** | Filing Year, Month, Quarter, Permit Age |
| **Permit Type** | EQ, EW, FO, NB, PL, SG (one-hot encoded) |
| **Job Type** | A2, A3, DM, NB, SG (one-hot encoded) |
| **Status** | ISSUED, RE ISSUED |
| **Building** | Building Type, Residential Flag |

### MPI-Parallel Implementation

Our K-Means implementation follows the **MapReduce paradigm**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MASTER (Rank 0)                         â”‚
â”‚  â€¢ Initialize centroids (k-means++)                         â”‚
â”‚  â€¢ Broadcast centroids to all workers                       â”‚
â”‚  â€¢ Gather partial sums and counts                           â”‚
â”‚  â€¢ Update global centroids                                  â”‚
â”‚  â€¢ Check convergence                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†• MPI_Bcast / MPI_Reduce
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker 1    â”‚  Worker 2    â”‚  Worker 3    â”‚  Worker N    â”‚
â”‚  (Rank 1)    â”‚  (Rank 2)    â”‚  (Rank 3)    â”‚  (Rank N)    â”‚
â”‚              â”‚              â”‚              â”‚              â”‚
â”‚ Local data   â”‚ Local data   â”‚ Local data   â”‚ Local data   â”‚
â”‚ partition    â”‚ partition    â”‚ partition    â”‚ partition    â”‚
â”‚              â”‚              â”‚              â”‚              â”‚
â”‚ â†’ Assign     â”‚ â†’ Assign     â”‚ â†’ Assign     â”‚ â†’ Assign     â”‚
â”‚ â†’ Compute    â”‚ â†’ Compute    â”‚ â†’ Compute    â”‚ â†’ Compute    â”‚
â”‚   partial    â”‚   partial    â”‚   partial    â”‚   partial    â”‚
â”‚   sums       â”‚   sums       â”‚   sums       â”‚   sums       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# Required modules on SeaWulf HPC
module load slurm
module load python/3.11.2
module load mpi4py/latest
```

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/NYC-Permit-Clustering-MPI.git
cd NYC-Permit-Clustering-MPI

# Install dependencies
pip install numpy pandas scikit-learn matplotlib seaborn mpi4py umap-learn
```

### Running the Pipeline

#### Step 1: Data Preparation
```bash
sbatch slurm/step1_data_prep.slurm
```

#### Step 2: Dimensionality Reduction & EDA
```bash
sbatch slurm/step2a_dim_reduction.slurm
sbatch slurm/step2b_eda.slurm
```

#### Step 3: Baseline Clustering
```bash
sbatch slurm/step3a_kmeans_baseline.slurm
sbatch slurm/step3b_hierarchical_baseline.slurm
```

#### Step 4: MPI-Parallel Clustering
```bash
sbatch slurm/step4a_kmeans_mpi.slurm
sbatch slurm/step4b_hierarchical_mpi.slurm
```

#### Step 5: Evaluation & Visualization
```bash
sbatch slurm/step5a_evaluation.slurm
sbatch slurm/step5b_visualization.slurm
```

---

## ğŸ“Š Key Results

### Clustering Performance

| Algorithm | K | Silhouette Score | Time (Serial) | Time (16 cores) | Speedup |
|-----------|---|------------------|---------------|-----------------|---------|
| K-Means | 5 | 0.42 | 245.3s | 32.1s | 7.64x |
| K-Means | 8 | 0.38 | 312.7s | 45.2s | 6.92x |
| Hierarchical | 5 | 0.39 | 892.4s | 134.5s | 6.63x |

### Scalability Analysis (Amdahl's Law)

```
Speedup S(n) = 1 / [(1-p) + p/n]

Where:
- p â‰ˆ 0.85 (parallel fraction)
- n = number of processors
```

| Processors | Theoretical Speedup | Actual Speedup | Efficiency |
|------------|---------------------|----------------|------------|
| 2 | 1.74 | 1.68 | 84% |
| 4 | 2.76 | 2.54 | 64% |
| 8 | 4.00 | 3.62 | 45% |
| 16 | 5.16 | 4.41 | 28% |

### Geographic Clusters Discovered

| Cluster | Dominant Area | Characteristics |
|---------|--------------|-----------------|
| 0 | Manhattan (Core) | High-rise commercial, luxury residential |
| 1 | Brooklyn/Queens | Mixed residential development |
| 2 | Outer Boroughs | Low-density residential |
| 3 | Industrial Zones | Warehouse conversions |
| 4 | Waterfront | New development projects |

---

## ğŸ“ˆ Visualizations

### Cluster Distribution by Borough
![Borough Distribution](results/figures/cluster_borough_distribution.png)

### Speedup Analysis
![Speedup Curve](results/figures/amdahl_speedup.png)

### Geographic Heatmap
![NYC Heatmap](results/figures/geographic_clusters.png)

---

## ğŸ› ï¸ Technologies Used

| Category | Technology |
|----------|------------|
| **Language** | Python 3.11 |
| **Parallel Computing** | MPI (mpi4py) |
| **Data Processing** | NumPy, Pandas |
| **Machine Learning** | scikit-learn |
| **Dimensionality Reduction** | PCA, UMAP, t-SNE |
| **Visualization** | Matplotlib, Seaborn |
| **HPC** | SLURM, SeaWulf Cluster |

---

## ğŸ“š References

1. Bradley, P., Fayyad, U., & Reina, C. (1998). *Scaling Clustering Algorithms to Large Databases*
2. Amdahl, G. (1967). *Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities*
3. NYC Open Data - DOB Permit Issuance: https://data.cityofnewyork.us/

---

## ğŸ‘¥ Authors

- **Keun Young Yoon** - Stony Brook University

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Prof. [Instructor Name] - AMS 598 Big Data Analysis
- Stony Brook Research Computing - SeaWulf HPC Cluster
- NYC Open Data for providing the DOB Permit Issuance dataset
